# -*- coding: utf-8 -*-
"""Assignment03.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-6nJVfS2m5hIz-JlOGI8kIqWTzgFMtOt
"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import train_test_split
from sklearn import metrics
import matplotlib.pyplot as plt  
import seaborn as seabornInstance 
from google.colab import files
import numpy as np
import pandas as pd
from sklearn import preprocessing
from sklearn.metrics import mean_absolute_error
import io
import requests
from sklearn.metrics import mean_squared_error

from sklearn.datasets import make_regression
from matplotlib import pyplot as plt
import numpy as np
from sklearn.linear_model import LinearRegression

# Car Evaluation
# Read Data into DF
car_url = "https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data"
columns = ["buying", "maint", "doors", "persons", "lug_boot", "safety", "class"]
data = pd.read_csv(car_url, names=columns, na_values=["?"])
# Cleaning up data
data[data.isnull().any(axis=1)]
cleanup_temp = {"buying": {"vhigh": 4, "high": 3, "med": 2, "low": 1},
                "maint": {"vhigh": 4, "high": 3, "med": 2, "low": 1},
                "doors": {"2": 1, "3": 2, "4": 3, "5more": 4},
                "persons": {"2": 1, "4": 2, "more": 3},
                "lug_boot": {"big": 3, "med": 2, "small": 1},
                "safety": {"high": 3, "med": 2, "low": 1}
                  }
cleanup_data = data
cleanup_data.replace(cleanup_temp, inplace=True)
cleanup_data.to_numpy

# Ready to parse that in the classifier
features,y, targets = np.hsplit(cleanup_data,np.array([6,6]))

train_data, test_data, train_targets, test_targets = train_test_split(features, targets, test_size=.3)

classifier = KNeighborsClassifier(n_neighbors=3)
classifier.fit(train_data, train_targets)
predictions = classifier.predict(test_data)

# Print out prediction
result = np.equal(test_targets.to_numpy().flatten(), predictions)
accuracy = np.count_nonzero(result == 1) / len(predictions)

accuracy

# Auto-mat Evaluation
# Read Data into DF
auto_url = "https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data"
columns = ["mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "name"]
auto_data = pd.read_csv(auto_url, names=columns ,delim_whitespace=True,  skipinitialspace=True, na_values=["?"])

mean = int(auto_data.mean(axis= 0,skipna = True, numeric_only=True).horsepower)

auto_data = auto_data.fillna(mean)

auto_data = pd.get_dummies(auto_data, columns=["name"])

targets, features, y= np.hsplit(auto_data,np.array([1,313]))

std_scale = preprocessing.StandardScaler().fit(features)
df_std = std_scale.transform(features)

train_data, test_data, train_targets, test_targets = train_test_split(df_std, targets, test_size=.3)

regr = KNeighborsRegressor(n_neighbors=3)
regr.fit(train_data, train_targets)

predictions = regr.predict(test_data)

df = pd.DataFrame({'Actual': test_targets.to_records(index=False).flatten(), 'Predicted': predictions.flatten()})

print ('MSE = ' , mean_squared_error(test_targets, predictions))
print ('MAE = ', mean_absolute_error(test_targets, predictions))
lr = LinearRegression()
lr.fit(test_data, predictions)
w = lr.coef_[0]
plt.plot(test_data, w*test_data, c='green')

# Student-mat Evaluation
# Read Data into DF
url = "https://raw.githubusercontent.com/ChillKids/CSE450ML-DM/master/Ponder/student-mat.csv"
s=requests.get(url).content
df = pd.read_csv(io.StringIO(s.decode('utf-8')),sep = ";", na_values=["?"])

df1 = df.iloc[:, :32]
df2 = df.iloc[:, 32:]


std_scale = preprocessing.StandardScaler().fit(df1[['age', 'famrel','freetime','goout','Dalc','Walc','health','absences','G1','G2']])
df1_std = std_scale.transform(df1[['age', 'famrel','freetime','goout','Dalc','Walc','health','absences','G1','G2']])


df1[["schoolsup", "famsup", "paid", "activities", "nursery", "higher", "internet", "romantic"]] = (df1[["schoolsup", "famsup", "paid", "activities", "nursery", "higher", "internet", "romantic"]] == 'yes').astype(int)
df1["famsize"] = (df1["famsize"] == 'GT3').astype(int)
df1["school"] = (df1["school"] == 'GP').astype(int)
df1["sex"] = (df1["sex"] == 'M').astype(int)
df1["address"] = (df1["address"] == 'U').astype(int)
df1["Pstatus"] = (df1["Pstatus"] == 'T').astype(int)
df1[['G1','G2']] = df1[['G1','G2']].astype(int)

#[['age', 'famrel','freetime','goout','Dalc','Walc','health','absences','G1','G2']]
df1 = pd.get_dummies(df1, columns=["Mjob","Fjob","reason","guardian"])

std_scale = preprocessing.StandardScaler().fit(df1)
df1 = std_scale.transform(df1)

train_data, test_data, train_targets, test_targets = train_test_split(df1, df2.to_numpy(), test_size=.3)

regr = KNeighborsRegressor(n_neighbors=3)
regr.fit(train_data, train_targets)

predictions = regr.predict(test_data)

print ("MSE = ", mean_squared_error(test_targets, predictions))
print ("MAE = ", mean_absolute_error(test_targets, predictions))

lr = LinearRegression()
lr.fit(test_data, predictions)
w = lr.coef_[0]
plt.plot(test_data, w*test_data, c='green')