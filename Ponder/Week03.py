# -*- coding: utf-8 -*-
"""Assignment03.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-6nJVfS2m5hIz-JlOGI8kIqWTzgFMtOt
"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import train_test_split
from sklearn import metrics
import matplotlib.pyplot as plt  
import seaborn as seabornInstance 
from google.colab import files
import numpy as np
import pandas as pd
from sklearn import preprocessing

# Car Evaluation
# Read Data into DF
car_url = "https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data"
columns = ["buying", "maint", "doors", "persons", "lug_boot", "safety", "class"]
data = pd.read_csv(car_url, names=columns, na_values=["?"])
# Cleaning up data
data[data.isnull().any(axis=1)]
cleanup_temp = {"buying": {"vhigh": 4, "high": 3, "med": 2, "low": 1},
                "maint": {"vhigh": 4, "high": 3, "med": 2, "low": 1},
                "doors": {"2": 1, "3": 2, "4": 3, "5more": 4},
                "persons": {"2": 1, "4": 2, "more": 3},
                "lug_boot": {"big": 3, "med": 2, "small": 1},
                "safety": {"high": 3, "med": 2, "low": 1}
                  }
cleanup_data = data
cleanup_data.replace(cleanup_temp, inplace=True)
cleanup_data.to_numpy

# Ready to parse that in the classifier
features,y, targets = np.hsplit(cleanup_data,np.array([6,6]))

train_data, test_data, train_targets, test_targets = train_test_split(features, targets, test_size=.3)

classifier = KNeighborsClassifier(n_neighbors=3)
classifier.fit(train_data, train_targets)
predictions = classifier.predict(test_data)

# Print out prediction
result = np.equal(test_targets.to_numpy().flatten(), predictions)
accuracy = np.count_nonzero(result == 1) / len(predictions)

accuracy

# Auto-mat Evaluation
# Read Data into DF
auto_url = "https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data"
columns = ["mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin", "name"]
auto_data = pd.read_csv(auto_url, names=columns ,delim_whitespace=True,  skipinitialspace=True, na_values=["?"])

mean = int(auto_data.mean(axis= 0,skipna = True, numeric_only=True).horsepower)

auto_data = auto_data.fillna(mean)

auto_data = pd.get_dummies(auto_data, columns=["name"])

targets, features, y= np.hsplit(auto_data,np.array([1,313]))

std_scale = preprocessing.StandardScaler().fit(features)
df_std = std_scale.transform(features)

train_data, test_data, train_targets, test_targets = train_test_split(df_std, targets, test_size=.3)

regr = KNeighborsRegressor(n_neighbors=3)
regr.fit(train_data, train_targets)

predictions = regr.predict(test_data)

df = pd.DataFrame({'Actual': test_targets.to_records(index=False).flatten(), 'Predicted': predictions.flatten()})
df

# ...
# ... code here to load a training and testing set
# ...

classifier = KNeighborsClassifier(n_neighbors=3)
classifier.fit(train_data, train_target)
predictions = classifier.predict(test_data)

# ...
# ... code here to load a training and testing set
# ...

regr = KNeighborsRegressor(n_neighbors=3)
regr.fit(train_data, train_target)
predictions = regr.predict(test_data)